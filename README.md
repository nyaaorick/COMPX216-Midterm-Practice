# COMPX216-Midterm

**七、 连续空间中的局部搜索 (Local Search in Continuous Spaces)**

* **1. 连续状态空间 (Continuous State Spaces)**
    * **精简核心概念：** 直接点出“状态由实数向量描述，可在值域内平滑无限变化”，与离散空间对比“离散可数、邻居明确；连续无限、依赖微积分分析”。
    * **目标函数：** 保留“优化依赖于状态向量 $x$ 的连续目标函数 $f(x)$”。
    * **生活例子：** 保留一个即可，例如“调节收音机音量”。
* **2. 梯度下降 (Gradient Descent)**
    * **目标：** 清晰指出“迭代优化算法，寻找函数局部最小值”。
    * **梯度：** 核心是“梯度向量指向函数值增加最快方向”，其分量是“偏导数”。
    * **核心思想：** 概括为“沿负梯度方向（最陡峭下降）小步移动，逼近局部最小值”。
    * **更新规则：** 公式 $x_{new} = x_{current} - \gamma \nabla f(x_{current})$ 必须保留。对各符号的解释可以更简洁：$x_{current}$ (当前状态), $\nabla f(x_{current})$ (当前梯度), $\gamma$ (学习率/步长，控制移动距离，过小则慢，过大则震荡或发散), “-” (向梯度反方向移动)。
    * **迭代过程与多维梯度下降：** 可以合并说明，核心是“从初始点重复应用更新规则直至满足停止条件。多维情况下，各分量独立按其偏导数更新”。
    * **练习题关联：** 直接点出“期中练习B.3e：梯度下降改为梯度上升，关键是更新规则中‘-’变为‘+’”。
* **4. 超越基本梯度下降 (Going beyond basic gradient descent)**
    * **学习率选择：** 概括为“固定学习率简单但非最优，可用线性搜索动态寻优”。
    * **利用二阶信息：**
        * 点明“梯度（一阶）提供斜率，Hessian矩阵（二阶）提供曲率（斜率变化）”。
        * “利用曲率可更智能选择步长和方向，加速收敛”。
        * **牛顿法：** “经典二阶方法，用梯度和Hessian逆更新，收敛快（若初始点合适且Hessian可逆正定）”。
        * **拟牛顿法：** “近似Hessian逆，降低计算复杂度”。
    * **约束优化：** 指出“实际问题常有变量约束，需专门算法（如拉格朗日乘子法），基本梯度下降不直接处理”。

**进化算法 (Evolutionary Algorithms)**

* **1. 基本思想**
    * **核心概念：** 精简为“受生物进化‘自然选择、遗传变异’启发的优化算法，模拟‘适者生存’改进解的质量”。
    * **过程概述：** 列表项可以更简洁：
        1.  **种群 (Population)：** 多个“个体 (individuals)”（潜在解）。
        2.  **适应度评估 (Fitness Evaluation)：** “适应度函数”评估个体优劣。
        3.  **选择 (Selection)：** 高适应度个体作“父代 (parents)”。
        4.  **繁殖 (Reproduction)：** 父代通过“交叉 (crossover)”（基因交换组合）和“突变 (mutation)”（基因随机小修改）产生“子代 (offspring)”。
        5.  **新一代种群：** 子代形成或与部分父代组成新种群。
        6.  **迭代：** 重复2-5直至满足终止条件。
    * **与局部搜索的联系：** “并行搜索，同时在多点探索与利用，通过种群交互和遗传操作探索更广空间”。
* **2. 核心组成与设计选项**
    * **初始化：** “通常随机生成，需保证多样性”。
    * **终止条件：** 列举关键几种即可，如“达到适应度阈值、最大代数、多样性过低、适应度不再提升”。
    * **适应度函数：** “即目标函数，评估解的质量，引导进化方向 (练习题 A.6)”。
    * **种群：** “一组潜在解。大小 (k) 影响探索与收敛；多样性避免早熟”。
    * **个体表示：** “问题解的编码（基因串/结构）”。列举几种典型算法及其表示法，如：
        * **遗传算法 (GAs)：** 字符串（二进制串等）。染色体 (个体/解)，基因 (解的组成部分)。
        * **进化策略 (ES)：** 实数向量。
        * **遗传编程 (GP)：** 程序（树结构）。
        * **进化编程 (EP)：** 有限状态机。
    * **父代数量：** “通常两个（模拟有性繁殖）”。
    * **选择操作：** “高适应度个体更大概率被选为父代”。列举几种核心方法，并简述其机制：
        * **轮盘赌：** 概率与适应度成正比。
        * **锦标赛：** 随机选几个，最优者胜出。
        * **排序选择：** 基于排名而非适应度值分配概率。
        * **精英保留：** 最优个体直接复制到下一代。
        * **剔除 (Culling)：** 移除差的个体。
* **3. 主要遗传操作**
    * **交叉/重组：**
        * **目的：** “组合父代优良基因，产生更优子代，主要探索手段 (练习题 B.1d)”。
        * **过程：** “交换父代部分基因片段形成子代”。
        * **常见方式（字符串）：** 单点交叉（随机点，一父供前，另一供后）。
        * **交叉率：** “控制交叉父代比例”。
    * **突变：**
        * **目的：** “子代基因随机小变动，增多样性，助跳出局部最优，另一探索机制”。
        * **过程：** “以突变率随机改变基因值（如二进制0/1互换）”。
        * **突变率：** “控制基因突变概率，通常较低。过高破坏优良基因，过低多样性不足”。
* **4. 遗传算法 (Genetic Algorithm, GA) 概述**
    * “最著名和常用的进化算法”。
    * **伪代码：** 指明参考幻灯片，概括步骤：初始化 -> 循环（评估 -> 选择 -> 交叉 -> 突变 -> 形成新种群）-> 返回最佳个体。
    * **8-皇后问题示例：** “展示编码、适应度函数、遗传操作应用”。
* **5. 理论考量**
    * **模式 (Schema)：** “带通配符的基因模板，代表相似个体组”。
    * **模式定理 (Building block hypothesis)：** “核心理论：适应度高、短、低阶的模式（积木块）指数级增长、组合，引导寻优”。
    * **表示的重要性：** “好的编码使有意义的解组件对应紧凑且不易被交叉破坏的基因片段，利于积木块保留组合”。
* **7. 应用实例**
    * “成功应用于复杂设计问题，如NASA进化天线”。

**局部搜索和优化 (Local Search and Optimisation)**

* **1. 优化问题 vs. 路径搜索**
    * **核心区别：**
        * **路径搜索：** 目标是“行动序列”，关心“如何到达”及“路径代价”。例：地图导航。
        * **优化问题：** 目标是“最优状态”，关心“最终状态好坏”，不关心路径。例：背包问题。
    * **目标函数/代价函数：** “评估状态优劣。最大化问题/最小化问题。代价函数通常指最小化”。
* **2. 局部搜索算法**
    * **特点：** “不保留路径，内存消耗小（仅当前状态），非系统性，易陷局部最优”。
    * **状态空间地貌：** “状态空间比作地形图，状态对应点，目标函数值对应高度。局部搜索如在地形上行走寻最值点”。
* **3. 爬山算法 (Hill-Climbing Search)**
    * **基本思想：** “贪婪局部搜索。从初始状态持续向邻居中值更优（高/低）的状态移动，至无更优邻居（山顶）则停止”。
    * **最陡峭上升爬山法：** “标准形式，选择改善幅度最大的邻居”。
    * **问题/缺点 (练习题 B.3a)：**
        * **局部最值：** “易陷入，比周围好但非全局最优 (练习题B.3a解释局部最值与目标函数关系)”。
        * **山脊：** “狭长区域，每步改进小或需特定序列，最陡峭上升难导航”。
        * **平顶/高原：** “平坦区域，邻居与当前状态值相同，算法随机游走或卡住”。
    * **N-皇后问题示例：** “爬山法（尤其带随机重启）可有效解决。状态：皇后摆放。目标函数：最小化攻击对数”。
* **4. 爬山算法的变体**
    * **目的：** “尝试克服标准爬山法易陷局部最优的问题”。
    * **随机重启爬山法 (练习题 A.5)：** “多次从不同随机初始状态运行标准爬山，取所有局部最优中的最佳者。显著增加找到全局最优概率”。
    * **随机爬山法：** “从所有改善邻居中随机选一个。选择概率可与改善幅度成正比。比最陡峭慢，但某些情况（如多平顶）可能更好”。
    * **首选爬山法 (练习题 B.3b)：** “当评估所有邻居代价高时适用。随机逐个生成邻居，找到首个更优者即移动。减少计算成本，邻居空间巨大时有用 (练习题B.3b)”。
* **5. 模拟退火 (Simulated Annealing)**
    * **思想来源：** “借鉴金属退火，高温加热后缓慢冷却，原子排列到低能稳定结构”。
    * **核心机制：**
        * “随机化局部搜索”。
        * **允许“坏”移动：** “以一定概率接受使目标函数值变差的移动”。
        * **接受概率：** 取决于“移动有多坏 ($\Delta E < 0$，下降越多概率越小)”和“温度 ($T$)，越高接受坏移动概率越大”。
        * **温度调度：** “初温高，广泛探索，易跳出局部最优；随时间降温，趋向只接受好移动，精细利用 (练习题 B.3c关注温度作用)”。
    * **目标：** “通过初期探索和后期利用，期望找到全局最优或近优解”。
* **6. 局部集束搜索 (Local Beam Search)**
    * **思想：** “并行跟踪 $k$ 个状态”。
    * **过程：** “随机生成 $k$ 个初始状态 -> 迭代中生成 $k$ 个状态的所有邻居 -> 从所有邻居中选最优 $k$ 个作下一轮状态 -> 重复至满足停止条件”。
    * **与随机重启爬山区别：** “随机重启是 $k$ 次独立搜索；局部集束中 $k$ 个状态信息共享（选所有邻居中最好的 $k$ 个），资源更集中于有希望区域”。
    * **变体：随机集束搜索：** “按评估值概率选 $k$ 个，增多样性”。

**有信息（启发式）搜索策略 (Informed (Heuristic) Search Strategies)**

* **1. 启发式函数 (Heuristic Function, $h(n)$)**
    * **定义与目的 (练习题 A.4)：** “评估函数，估计从节点 $n$ 到目标的最低代价。非精确，是‘有根据的猜测’。提供方向感，引导优先探索‘看起来’更近的路径，提高效率 (练习题B.2a)”。
    * **与无信息搜索区别：** “无信息仅用问题本身信息；有信息通过 $h(n)$ 利用领域特定知识”。
* **2. 贪婪最佳优先搜索 (Greedy Best-First Search)**
    * **策略 (练习题 A.3c)：** “贪婪算法，总选择边界中 $h(n)$ 评估为最接近目标的节点。评估函数 $f(n)=h(n)$，忽略已付出代价 $g(n)$”。
    * **工作方式：** “优先队列（按 $h(n)$ 排序）管理边界，取 $h(n)$ 最小节点扩展”。
    * **特性：** “完备性：有限图完备，无限/有环图（无重复检测）可能不完备。最优性：通常不优，可能被‘陷阱’吸引。复杂度：好启发式可显著减少节点”。
* **3. A\* 搜索 (A\* Search)**
    * **策略 (练习题 A.3b)：** “兼顾已付出代价和未来预估代价。评估函数 $f(n)=g(n)+h(n)$。总选择边界中 $f(n)$ 最小节点扩展”。
    * **工作方式：** “优先队列（按 $f(n)$ 排序）。扩展子节点时计算 $g(child)$ 和 $f(child)$。若找到更优路径到达已存在节点，需更新”。
    * **可接受的启发式 (Admissible Heuristics) (练习题 B.2a, B.2e)：**
        * **定义：** “对所有节点 $n$，从不 overestimate (高估)到目标的实际最低代价 $h^*(n)$。即 $0 \le h(n) \le h^*(n)$”。
        * **重要性：** “若 $h(n)$ 可接受，A\* 保证最优”。
    * **一致的启发式 (Consistent Heuristics / Monotonicity) (练习题 B.2e)：**
        * **定义：** “对每节点 $n$ 及子节点 $n'$（行动 $a$，代价 $c(n,a,n')$），满足 $h(n) \le c(n,a,n') + h(n')$。且 $h(goal)=0$”。
        * **特性：** “一致则可接受。A\* 效率更高：一旦节点被扩展，即找到最优路径。$f(n)$ 值沿路径非递减 (练习题B.2e保证)”。
    * **搜索等高线：** “UCS均匀扩展（圆形）；A\* 集中朝目标扩展（椭圆形），体现启发式‘聚焦’”。
    * **特性：** “完备性：是。最优性：$h(n)$ 可接受时最优；一致则效率更高。最优效率：同启发式下扩展节点最少”。
* **4. 启发式的创建**
    * **核心挑战：** “好的启发式应：可接受（保证最优），信息量大（$h(n)$ 近似 $h^*(n)$，有效指导），计算成本低”。
    * **常用方法：**
        * **松弛问题：** “移除约束简化问题，其精确代价可作可接受启发式”。例：8-puzzle错位棋子数、曼哈顿距离。
        * **模式数据库：** “预存子问题最优解代价作启发式”。
    * **8-puzzle启发式例子：** “$h_1(n)$ = 错位棋子数 (可接受)；$h_2(n)$ = 曼哈顿距离和 (可接受，通常更优)”。
* **5. 内存有界搜索**
    * **问题：** “A\* 等算法大状态空间下内存可能耗尽”。
    * **集束搜索 (Beam Search) (练习题 A.9)：**
        * “启发式搜索，每步只保留固定数量 ($k$, 集束宽度)最有希望节点”。
        * **过程：** “生成后继 -> 评估 -> 只保留最优 $k$ 个，其余丢弃 -> 从 $k$ 个中选节点扩展”。
        * **优缺点：** “显著减内存；不完备且不保证最优 (可能丢弃最优路径上节点) (练习题A.9考察)”。

**无信息搜索策略 (Uninformed Search Strategies)**

* **1. 无信息 vs. 有信息搜索**
    * **无信息：** “无特定知识指导，仅区分目标/非目标，系统性探索（如BFS逐层，DFS深入）”。
    * **有信息：** “用 $h(n)$ 估计到目标距离/代价，优先扩展有希望节点”。
* **2. 通用最佳优先搜索 (Generic Best-First Search)**
    * **框架：** “多种搜索算法特例”。
    * **核心思想：** “维护边界 (frontier, 已生成未扩展节点) -> 据策略/评估函数选‘最佳’节点扩展 -> 若目标则返回解 -> 否则扩展子节点入边界 -> 重复”。
    * **区别：** “选择策略及边界管理方式（队列类型）”。
    * **已达到列表 (reached list / explored set)：** “避免循环和冗余工作，存已扩展/已入边界状态”。
* **3. 广度优先搜索 (BFS)**
    * **策略 (练习题 A.3, B.2c(a))：** “总扩展边界中最浅节点。逐层探索”。
    * **数据结构：** “FIFO队列管理边界 (练习题B.2c(a))”。
    * **特性：** “完备性：是。最优性：仅当所有步代价相同时最优（路径最短）。时空复杂度：$O(b^d)$ (空间是主要缺点)”。
* **4. 一致代价搜索 (UCS) (Dijkstra)**
    * **策略 (练习题 B.2b)：** “总扩展路径代价 $g(n)$ 最低节点。不关心深度，只关心累积代价”。
    * **数据结构：** “优先队列（按 $g(n)$ 排序）”。
    * **特性：** “完备性：是（若步代价 $\epsilon > 0$）。最优性：是（若步代价非负）。时空复杂度：大致 $O(b^{1+\lfloor C^*/\epsilon \rfloor})$”。
    * **与BFS关系：** “若步代价相同，UCS等同BFS”。
* **5. 深度优先搜索 (DFS)**
    * **策略 (练习题 B.2c(b))：** “总扩展边界中最深节点。沿路径探到底再回溯”。
    * **数据结构：** “LIFO队列（栈）管理边界 (练习题B.2c(b))”。
    * **特性：** “完备性：有限图完备；无限深/有环图（无重复检测）可能不完备。最优性：通常不优。时间复杂度：最坏 $O(b^m)$。空间复杂度：$O(bm)$ (主要优点)”。
    * **变体：** 深度限制搜索 (DLS)，迭代加深搜索 (IDDFS, 结合BFS最优和DFS空间效率)。
* **6. 避免重复状态**
    * **问题：** “冗余计算，有环图无限循环”。
    * **解决方案：** “维护已达到列表 (哈希表实现)。Tree-Search不检测重复；Graph-Search维护已探索集”。
* **7. 队列的角色和实现 (练习题 B.2d)**
    * **核心：** “不同队列类型实现边界 -> 不同搜索行为”。
        * FIFO -> BFS (最浅)
        * LIFO -> DFS (最深)
        * 优先队列 (按 $g(n)$) -> UCS (路径代价最低)
        * 优先队列 (按 $h(n)$) -> Greedy Best-First
        * 优先队列 (按 $f(n)=g(n)+h(n)$) -> A\*
    * **练习题关联 (B.2d)：** “优先队列 + 深度评估 -> BFS；优先队列 + 负深度评估 -> DFS”。

**问题解决型智能体 (Problem-Solving Agents)**

* **1. 智能体与环境**
    * **单智能体 vs. 多智能体 (练习题 B.1b)：** “单：独行；多：多个体交互（合作/竞争）。关键：环境是否有其他目标导向实体影响当前智能体”。
    * **确定性 vs. 非确定性/随机性：** “确定：下一状态完全由当前状态和动作决定；非确定：含随机因素，或部分可观察导致”。
    * **片段性 vs. 序列性：** “片段：决策独立于历史；序列：当前决策影响未来，历史重要”。
    * **静态 vs. 动态 (练习题 A.2)：** “静态：智能体决策时环境不变；动态：决策时环境可能变化”。
    * **离散 vs. 连续：** “应用于状态、时间、感知、行动。离散：有限可数；连续：无限多值”。
* **2. 问题定义与形式化**
    * **问题解决型智能体：** “通过搜索行动序列达目标。通常原子状态表示，环境简化假设（全可观察、单体、确定等）”。
    * **问题解决过程：** “目标制定 -> 问题形式化 -> 搜索 -> 执行”。
    * **搜索问题组成 (练习题 B.1a)：**
        * **状态空间 (States)：** 所有可能状态集合。
        * **初始状态 (Initial state)：** 搜索起点。
        * **目标测试 (Goal test)：** 判断是否目标状态。
        * **行动 (Actions)：** 给定状态下可执行行动集。
        * **转移模型 (Transition model/Successor function)：** $RESULT(s, a) \rightarrow s'$，执行行动后状态转换。
        * **路径代价函数 (Path cost function)：** 行动数值代价，解的代价是路径上行动代价和。最优解代价最低。
* **3. 搜索树与数据结构**
    * **状态空间图 vs. 搜索树：** “图：状态及转换关系抽象，状态唯一；树：搜索中动态构建，节点对应到达状态的路径，同状态可多次出现”。
    * **节点 (Node) 构成 (练习题 B.1c)：** “记录搜索过程和重构解。含：state, parent, action, path\_cost ($g(n)$), depth。状态是环境配置；节点是含状态和路径信息的数据结构”。
    * **节点扩展 (Expanding nodes)：** “选边界节点，生成其所有子节点加入边界”。
    * **边界 (Frontier)：** “已生成未扩展节点。核心区别在于如何从中选择及管理”。
    * **已探索集合 (Explored set)：** “已访问状态，避免重复探索和循环”。
* **4. 搜索策略评估标准**
    * **完备性 (Completeness)：** 是否保证找到解？
    * **最优性 (Optimality)：** 是否找到路径代价最低的解？
    * **时间复杂度 (Time complexity)：** 找到解需多久（扩展节点数）？
    * **空间复杂度 (Space complexity)：** 需多少内存（边界最大节点数）？


**Section B 详细解析:**

**问题 1: Problem-solving Agents and Evolutionary algorithms (问题解决型智能体和进化算法) (25 分)**

* **a. Wumpus 世界 (7 分)**
    * **考查点:** 理解并能描述一个经典搜索问题的基本组成部分。你需要从题目描述的Wumpus世界中，挑选并解释以下六个组件中的任意三个：
        * **State space (状态空间):** 描述Wumpus世界中所有可能的状态。一个状态可能包括：智能体当前的位置 (例如在哪个格子)，Wumpus的位置，所有坑的位置，金子的位置，以及智能体是否还活着，是否拥有箭，Wumpus是否还活着等等。关键在于识别出所有能影响决策和结果的变量组合。
        * **Initial state (初始状态):** 根据题目描述，智能体通常从一个已知的、安全的方格开始，例如 `[1,1]`。此时智能体对其他格子的具体情况（Wumpus、坑、金子）是未知的 (除了规则本身)。
        * **Goal state (目标状态):** 题目明确指出目标是“找到金子并安全返回到起始方格”。所以目标状态是智能体持有金子并且位于起始方格 `[1,1]`，并且是活着的。
        * **Actions (行动):** 题目中列举了智能体可以执行的行动：“move forward (向前移动), turn left (向左转), turn right (向右转), grab (抓取), shoot an arrow (射箭)”。
        * **Transition model (转移模型):** 描述在某个状态下执行某个行动后，环境会如何变化。例如：
            * 在状态 `(Agent at [1,1] facing East, Gold at [2,1])` 执行 `Move Forward`，会转移到状态 `(Agent at [2,1] facing East, Gold at [2,1])`。
            * 如果智能体在Wumpus或坑旁边，执行 `Move Forward` 进入Wumpus或坑所在的格子，会导致智能体死亡（除非Wumpus已被杀死）。
            * 执行 `Grab` 时，如果当前格子有金子，则智能体获得金子。
            * 执行 `Shoot` 时，如果箭射向Wumpus所在的方向且路径上没有障碍，则Wumpus被杀死。
        * **Path cost function (路径代价函数):** 通常，每个行动会消耗一定的代价。在这个问题中，可以简单地假设每个行动的代价为1（例如，目标是找到最少行动次数的解），或者也可以根据具体情况定义不同的代价（例如，射箭的代价可能比移动高）。题目没有明确说明，你可以做一个合理的假设。
    * **答题策略:** 选择你最有把握描述清楚的三个组件。对于每个组件，结合Wumpus世界的具体情境进行解释，而不仅仅是给出抽象的定义。

* **b. 单智能体 vs. 多智能体环境 (5 分)**
    * **考查点:** 区分两种基本环境类型。
        * **Single-agent (单智能体):** 环境中只有一个智能体在行动和做决策。其性能度量只取决于自身的行动和环境的状态，不受其他智能体目标驱动行为的影响。例如，一个人玩单人纸牌游戏，或者一个机器人独自在一个封闭空间执行任务。
        * **Multi-agent (多智能体):** 环境中存在多个以目标为导向行动的实体（智能体）。这些智能体可能会相互影响，它们的行动会共同决定环境的下一个状态以及各个智能体的性能。多智能体可以是合作的（例如，一队机器人协同搬运物体），竞争的（例如，下棋的双方，或者足球比赛中的两队球员），或者是漠不关心的（例如，在公路上行驶的多辆自动驾驶汽车，它们有各自的目标，但行动会相互影响交通状况）。
    * **答题策略:** 清晰地给出两者的定义，并举例说明。关键在于强调“其他目标驱动行为的实体”的存在与否以及它们对当前智能体性能的影响。

* **c. 状态空间中的“状态” vs. 搜索树中的“节点” (5 分)**
    * **考查点:** 理解问题表示和搜索过程中的基本数据结构。
        * **State (状态):** 是问题所处环境的一种具体配置或快照。它描述了世界在某一时刻的所有相关方面。在状态空间图中，每个状态是唯一的。例如，在8-皇后问题中，棋盘上8个皇后的一种特定摆放就是一个状态。
        * **Node (节点):** 是搜索算法在构建搜索树时使用的数据结构，用于记录和追踪搜索过程。一个节点通常包含：
            * 对应的**状态 (state)**。
            * 指向其**父节点 (parent)** 的指针（表示是如何到达当前状态的）。
            * 导致从父节点状态转移到当前节点状态的**行动 (action)**。
            * 从初始状态到当前节点的**路径总代价 (path\_cost, $g(n)$)**。
            * 节点在搜索树中的**深度 (depth)**。
            同一个状态可能会在搜索树的不同分支或不同深度以不同的节点形式出现，因为到达同一个状态可能存在多条不同的路径。
    * **答题策略:** 明确两者的定义，并指出它们之间的关系：节点包含了状态以及到达该状态的路径等附加信息。状态是问题本身的属性，节点是搜索算法的产物。

* **d. 遗传算法中的交叉 (Crossover) (4 分)**
    * **考查点:** 理解遗传算法核心操作之一——交叉的概念和意义。
        * **What is crossover? (什么是交叉?)**: 交叉是遗传算法中一种主要的繁殖操作，它模拟生物进化中的基因重组。它通常选择两个（或多个）父代个体，然后通过交换它们的部分“基因”（即解决方案的编码片段）来产生一个新的子代个体（或多个子代）。常见的交叉方式有单点交叉、多点交叉、均匀交叉等。例如，在单点交叉中，随机选择一个交叉点，子代的前半部分基因来自一个父代，后半部分来自另一个父代。
        * **Significance of crossover (交叉的重要性/意义):**
            * **探索 (Exploration):** 交叉是遗传算法探索搜索空间的主要手段之一。通过组合不同父代的基因片段，它可以产生全新的、可能包含父代优良特征组合的子代，从而探索到父代本身未曾到达的区域。
            * **信息共享与组合 (Information Sharing and Combination):** 它允许算法将来自不同父代个体的“优良积木块”（好的基因组合）结合起来，期望产生比父代更优的解。
            * **加速收敛 (Potentially Accelerating Convergence):** 通过有效地组合好的解决方案的片段，交叉有助于算法更快地向更优解的方向收敛（相对于纯粹的随机搜索或仅依赖突变的搜索）。
    * **答题策略:** 先清晰定义交叉操作的过程，然后分点阐述其在遗传算法中的作用和重要性。

* **e. 进化算法与生物进化/自然选择的区别 (4 分)**
    * **考查点:** 对比理解进化算法与生物学概念的异同。虽然进化算法受生物进化启发，但它们是简化的、目标导向的计算模型。
        * **目标 (Purpose):**
            * **生物进化:** 主要目标是适应环境并在种群中繁衍后代，没有预设的“最优解”或明确的优化目标函数，是一个持续的、开放的过程。
            * **进化算法:** 通常用于解决特定的优化问题，有一个明确定义的适应度函数（目标函数），目标是找到使该函数最优（或次优）的解。
        * **表示 (Representation):**
            * **生物进化:** 基因表示是复杂的DNA序列，其功能和相互作用极其复杂。
            * **进化算法:** 个体（解）的表示通常是简化的，如二进制串、实数向量或树形结构，其“基因”的含义和作用是明确定义的。
        * **时间尺度 (Timescale):**
            * **生物进化:** 发生在非常长的时间尺度上（数百万年）。
            * **进化算法:** 在计算机上运行，时间尺度相对很短（秒、分钟、小时）。
        * **环境 (Environment):**
            * **生物进化:** 发生在真实的、动态的、不可预测的自然环境中。
            * **进化算法:** 通常在模拟的、受控的、确定性的（或可控随机性的）计算环境中运行。
        * **选择机制 (Selection Mechanism):**
            * **生物进化:** 自然选择是一个复杂的过程，受多种因素影响，包括生存压力、繁殖成功率等。
            * **进化算法:** 选择机制是明确定义的算法步骤（如轮盘赌、锦标赛选择），直接基于适应度函数的值。
        * **遗传操作的控制 (Control of Genetic Operators):**
            * **生物进化:** 交叉和突变的发生具有一定的随机性和自然规律。
            * **进化算法:** 交叉率和突变率等参数通常是人为设定和调整的，以优化算法性能。
    * **答题策略:** 从几个关键方面（如目标、表示、环境、选择机制等）对比两者的不同之处。

**问题 2: Uninformed and Informed Search (无信息和有信息搜索) (25 分)**

* **a. 启发式函数在A\*等算法中的作用 (4 分)**
    * **考查点:** 理解启发式函数的核心功能。
        * 启发式函数 $h(n)$ 在A\*这类有信息搜索算法中扮演着**指导搜索方向**的关键角色。
        * 它提供了一个从当前节点 $n$ 到目标状态的**估计代价 (estimated cost)**。
        * A\*算法的评估函数是 $f(n) = g(n) + h(n)$，其中 $g(n)$ 是从初始状态到节点 $n$ 的实际代价。通过将 $h(n)$（对未来代价的估计）加入到 $g(n)$（已付出代价）中，A\*算法能够优先扩展那些**看起来整体路径代价 $f(n)$ 更小的节点**。
        * 一个好的启发式函数可以显著**减少需要扩展的节点数量**，从而**提高搜索效率**，使得算法更快地找到解，尤其是在大型搜索空间中。
        * 如果启发式函数是**可接受的 (admissible)**（即从不 overestimate 到目标的实际代价），A\*算法能保证找到最优解。
    * **答题策略:** 解释启发式函数如何提供“有根据的猜测”，以及这种猜测如何被A\*算法用来引导搜索，最终达到提高效率和（在满足条件下）保证最优性的目的。

* **b. 为什么一致代价搜索 (UCS) 是无信息搜索方法 (4 分)**
    * **考查点:** 理解无信息搜索的定义，并将其应用于UCS。
        * 无信息搜索策略（也称盲目搜索）在选择下一个要扩展的节点时，**不使用任何关于“目标可能在哪个方向”或“哪个节点距离目标更近”的特定于问题的启发式信息**。它们仅仅依赖于问题本身的定义，如状态、行动、目标测试和路径代价。
        * 一致代价搜索 (UCS) 的策略是**总是扩展从初始状态到达该节点的路径代价 $g(n)$ 最低的未扩展节点**。
        * UCS 的决策完全基于**已经付出的实际路径代价 $g(n)$**，它并不知道哪个方向“看起来”更有希望到达目标。它像水波一样从起点向各个方向均匀扩展（以累积代价为半径）。
        * 因此，UCS 没有利用任何启发式函数 $h(n)$ 来估计到目标的未来代价，它符合无信息搜索的定义。
    * **答题策略:** 首先定义什么是无信息搜索，然后说明UCS的节点选择策略，并指出其选择依据中不包含启发式信息。

* **c. 用于实现BFS和DFS的简单队列 (6 分)**
    * **考查点:** 掌握BFS和DFS核心数据结构。
        * **(a) Breadth-First Search (BFS - 广度优先搜索):** 使用 **先进先出 (FIFO - First-In, First-Out) 队列** 来管理边界 (frontier)。新生成的节点（子节点）被添加到队列的末尾 (enqueue)，而下一个要扩展的节点从队列的头部 (dequeue) 取出。这保证了算法总是先扩展浅层的节点。
        * **(b) Depth-First Search (DFS - 深度优先搜索):** 使用 **后进先出 (LIFO - Last-In, First-Out) 队列**，也就是 **栈 (Stack)** 来管理边界。新生成的子节点被压入栈顶 (push)，下一个要扩展的节点从栈顶弹出 (pop)。这保证了算法总是沿着一条路径深入探索。
    * **答题策略:** 直接点明两种算法分别使用的队列类型，并可以简要说明该队列类型如何导致了各自的搜索行为。

* **d. 使用深度或负深度作为评估函数的搜索算法 (6 分)**
    * **考查点:** 理解通用最佳优先搜索框架如何通过不同的评估函数实例化为不同的搜索算法。这里假设优先队列总是选择评估函数值*最小*的节点。
        * **(a) 以节点的深度 (depth of a node) 作为评估函数返回值:**
            * 如果评估函数 $f(n) = \text{depth}(n)$，并且优先队列选择 $f(n)$ 最小的节点，那么浅层节点（深度小）会被优先选择。
            * 这与 **广度优先搜索 (BFS)** 的行为一致，因为BFS就是逐层扩展，总是先扩展深度最小的节点。
        * **(b) 以节点的负深度 (-depth of a node) 作为评估函数返回值:**
            * 如果评估函数 $f(n) = -\text{depth}(n)$，并且优先队列选择 $f(n)$ 最小的节点（即 $\text{depth}(n)$ 最大的节点），那么深层节点会被优先选择。
            * 这与 **深度优先搜索 (DFS)** 的行为一致，因为DFS就是尽可能深地探索路径。
    * **答题策略:** 对于每种情况，分析评估函数如何影响节点的选择顺序，并将其与已知的无信息搜索算法的行为联系起来。

* **e. 一致的启发式 (Consistent Heuristic) (5 分)**
    * **考查点:** 理解一致性启发式的定义及其重要保证。
        * **When is a heuristic considered "consistent"? (何时启发式被认为是“一致的”?)**
            * 一个启发式函数 $h(n)$ 被称为一致的（或满足单调性条件），如果对于每一个节点 $n$ 和由行动 $a$ 生成的任一子节点 $n'$，从 $n$ 到 $n'$ 的步骤代价为 $c(n,a,n')$，满足以下条件（也称为三角不等式）：
                $h(n) \le c(n,a,n') + h(n')$
            * 并且，对于任何目标节点 $goal$，有 $h(goal) = 0$。
            * 直观地讲，这意味着从一个节点到目标的估计代价，不应该大于通过其任一子节点到目标的估计代价加上到达该子节点的实际代价。也就是说，启发式函数的值在沿着任何路径从根节点向下时都是非递减的（如果考虑 $f(n)=g(n)+h(n)$ 的话）。
        * **What guarantee does this property provide when the heuristic is used in a search algorithm? (当该启发式用于搜索算法时，此属性提供什么保证?)**
            * **保证A\*算法的最优效率 (Guarantees optimal efficiency for A\*):** 当A\*算法使用一致的启发式时，一旦一个节点被选择进行扩展，A\*就已经找到了到达该节点状态的最优路径。这意味着这个节点不需要被重新打开或更新其路径代价。
            * **$f(n)$值的非递减性 (Non-decreasing $f(n)$ values):** 当使用一致的启发式时，沿着A\*搜索树的任何路径，$f(n)$ 的值是单调非递减的 ($f(n') \ge f(n)$ for successor $n'$ of $n$)。
            * **可接受性 (Admissibility):** 如果一个启发式是一致的，那么它也一定是可接受的。因此，使用一致启发式的A\*算法也保证找到最优解。
    * **答题策略:** 先给出一致性启发式的数学定义和直观解释，然后说明它对A\*算法行为（特别是找到路径即最优）和结果（保证最优解）的关键保证。

**问题 3: Local Search and Optimisation (局部搜索和优化) (20 分)**

* **a. 局部最大值 vs. 局部最小值 (5 分)**
    * **考查点:** 理解局部搜索中的基本概念及其与目标函数的关系。
        * **Local Maximum (局部最大值):** 在一个状态空间地貌中，一个局部最大值是一个状态，其目标函数值**大于或等于**其所有邻近状态的目标函数值。它就像一个小山峰，比周围的点都高（或一样高），但它不一定是整个状态空间中的最高点（即全局最大值）。如果优化目标是最大化目标函数，爬山算法等局部搜索算法很容易在达到一个局部最大值后停止，因为它无法通过查看邻居找到更好的状态。
        * **Local Minimum (局部最小值):** 相应地，一个局部最小值是一个状态，其目标函数值**小于或等于**其所有邻近状态的目标函数值。它就像一个小山谷的谷底，比周围的点都低（或一样低），但它不一定是整个状态空间中的最低点（即全局最小值）。如果优化目标是最小化目标函数，局部搜索算法可能会陷入局部最小值。
        * **Relation to the objective function (与目标函数的关系):** 局部最大值和局部最小值都是相对于**目标函数 (objective function)** 在当前状态及其邻近状态的取值而言的。目标函数定义了状态空间地貌的高度，局部搜索算法试图在这个地貌上找到最高点（最大化问题）或最低点（最小化问题）。局部最值是这些算法可能“卡住”的地方。
    * **答题策略:** 分别定义局部最大值和局部最小值，强调“邻近状态”和“不一定是全局”这两个关键点。然后解释它们是如何由目标函数在该点及其周围的值决定的。

* **b. 首选爬山法 (First-Choice Hill Climbing) (4 分)**
    * **考查点:** 理解一种爬山算法变体的机制、优点和适用场景。
        * **Describe the first-choice hill climbing algorithm (描述首选爬山法):** 首选爬山法是标准爬山算法（通常指最陡峭上升爬山法）的一个变体。在每一步，它不是评估所有邻居状态然后选择最好的那一个，而是**随机地逐个生成邻居状态**。一旦它找到**第一个**比当前状态更好的邻居（即目标函数值有改善），它就**立即移动到该邻居状态**，并停止生成和评估当前迭代中的其他邻居。
        * **Explain how it addresses some of the drawbacks of the standard hill climbing algorithm (解释它如何解决标准爬山算法的一些缺点):**
            * **减少评估成本 (Reduces evaluation cost):** 标准的最陡峭上升爬山法需要评估当前状态的所有邻居，这在邻居数量非常多（状态空间分支因子很大）的情况下计算成本会非常高。首选爬山法通过只评估直到找到第一个更好的邻居为止，显著减少了每一步的评估次数，从而节省了计算时间。
        * **When it is particularly useful and why (何时特别有用及其原因):**
            * 当**评估一个邻居状态的代价很高**或者**一个状态的邻居数量非常巨大**时，首选爬山法特别有用。因为它不需要遍历所有邻居，可以更快地做出决策并移动。例如，在某些问题中，生成一个邻居本身可能就需要复杂的计算。
    * **答题策略:** 清晰描述算法流程，重点突出“随机生成”和“找到第一个更好即移动”。然后解释其相对于标准爬山在计算成本上的优势，并明确其适用场景。

* **c. 用模拟退火设计健身计划 (4 分)**
    * **考查点:** 将模拟退火的概念应用于一个具体问题，并理解温度参数的作用。
        * **Describe how this problem can be addressed using Simulated Annealing (描述如何用模拟退火解决此问题):**
            1.  **状态表示 (State Representation):** 一个状态可以是一个完整的每日锻炼计划（例如，一周七天，每天安排的运动项目和时长）。
            2.  **目标函数/适应度函数 (Objective/Fitness Function):** 设计一个函数来评估一个锻炼计划的“好坏”。这个函数应该考虑：
                * **最大化运动多样性:** 例如，包含的运动种类越多越好。
                * **确保锻炼间隔:** 例如，对连续两天进行相同类型（如腿部）的锻炼进行惩罚。
                * **满足时间限制:** 例如，如果总锻炼时间超过限制，则给予大的惩罚（或者直接视为不可行解）。
                目标是找到使这个函数值最优（例如，最大化一个综合得分，或者最小化一个包含惩罚项的代价）。
            3.  **邻居操作 (Neighboring Moves):** 定义如何从一个锻炼计划（当前状态）生成一个邻近的计划。例如：
                * 随机改变某一天的运动项目。
                * 随机调整某一运动的时长。
                * 交换两天的锻炼安排。
            4.  **模拟退火过程:**
                * 从一个随机生成的锻炼计划开始。
                * 在每次迭代中，随机生成一个邻居计划。
                * 计算新计划与当前计划的目标函数值的差异 ($\Delta E$)。
                * 如果新计划更好（例如，目标函数值更高），则接受新计划。
                * 如果新计划更差，则根据接受概率 $P = e^{\Delta E / T}$ 来决定是否接受它。其中 $T$ 是当前的温度。
        * **Specifically focusing on the role of the temperature variable (特别关注温度变量的作用):**
            * **高温阶段 (High Temperature - 初期):** 在算法开始时，温度 $T$ 设置得较高。此时，即使新的锻炼计划比当前的差（例如，多样性略减，或者出现了一点点不希望的连续锻炼），算法也有较大的概率接受这个“坏”的移动。这使得算法能够进行**广泛的探索 (exploration)**，不容易过早陷入某个局部最优的计划中。它允许算法跳出那些看起来不错但可能并非全局最佳的方案，去尝试更多可能性。
            * **降温过程 (Cooling Schedule):** 随着迭代的进行，温度 $T$ 逐渐降低（根据预设的退火调度）。
            * **低温阶段 (Low Temperature - 后期):** 当温度 $T$ 变得很低时，算法接受“坏”移动的概率会大大降低。此时，算法更倾向于只接受那些能够改进当前计划的移动，从而在之前探索到的有希望的区域进行**精细的利用 (exploitation)**，逐步优化找到的最佳方案。
            * **平衡探索与利用 (Balancing Exploration and Exploitation):** 温度变量控制了算法在初期探索更多可能性（即使有些组合看起来不太好）和后期专注于优化最佳方案之间的平衡。
    * **答题策略:** 首先描述如何将健身计划问题映射到模拟退火的框架（状态、目标函数、邻居操作）。然后重点解释温度从高到低的变化如何影响算法接受“坏”移动的概率，以及这如何帮助算法平衡全局探索和局部优化。

* **d. 梯度下降是否总能找到全局最小值 (3 分)**
    * **考查点:** 理解梯度下降算法的局限性。
        * **No, the gradient descent algorithm does not always guarantee that it will find the global minimum of an objective function.** (不，梯度下降算法并不总是保证能找到目标函数的全局最小值。)
        * **Justify your answer (证明你的答案):**
            * **局部最小值 (Local Minima):** 梯度下降是一种**局部搜索算法**，它在每一步都沿着当前位置梯度的负方向（最陡峭下降方向）移动。如果目标函数有多个局部最小值，梯度下降算法可能会收敛到离初始点最近的或者在下降路径上遇到的第一个局部最小值，而这个局部最小值不一定是全局最小值。一旦算法到达一个局部最小值点（该点的梯度为零或接近零），它就无法再通过梯度信息找到更低的点，从而“卡住”。
            * **初始点依赖性 (Dependence on Initial Point):** 梯度下降最终收敛到哪个局部最小值，很大程度上取决于算法的**初始状态（起始点）**。从不同的初始点开始搜索，可能会得到不同的局部最小值。
            * **平坦区域或鞍点 (Plateaus or Saddle Points):** 在一些平坦区域（梯度很小）或者鞍点（某些方向上升，某些方向下降，但梯度可能为零），梯度下降的收敛速度可能会非常慢，或者可能在鞍点附近震荡。
    * **答题策略:** 明确回答“否”，然后从局部最小值、初始点依赖性等角度解释原因。

* **e. 将梯度下降代码修改为梯度上升 (4 分)**
    * **考查点:** 理解梯度下降和梯度上升的根本区别，并能将其反映在算法实现上。
        * **Key modification (关键修改):** 要将梯度下降算法修改为梯度上升算法，最关键的修改在于**更新规则 (update rule)** 中对梯度项的操作。
            * 在梯度下降中，更新规则通常是：$x_{new} = x_{current} - \gamma \nabla f(x_{current})$
            * 在梯度上升中，更新规则应该是：$x_{new} = x_{current} + \gamma \nabla f(x_{current})$
            即将梯度项前的**减号 (-) 改为加号 (+)**。
        * **Explain your reasoning (解释你的理由):**
            * **梯度的方向 (Direction of the Gradient):** 梯度 $\nabla f(x)$ 指向的是函数 $f(x)$ 在点 $x$ 处**增加最快**的方向（最陡峭上升方向）。
            * **梯度下降的目标 (Goal of Gradient Descent):** 梯度下降的目标是找到函数的**最小值 (minimum)**。因此，它需要向函数值**减小**的方向移动。负梯度 $-\nabla f(x)$ 指向函数值减少最快的方向，所以梯度下降沿着负梯度方向更新。
            * **梯度上升的目标 (Goal of Gradient Ascent):** 梯度上升的目标是找到函数的**最大值 (maximum)**。因此，它需要向函数值**增加**的方向移动。梯度本身 $\nabla f(x)$ 就指向函数值增加最快的方向，所以梯度上升直接沿着梯度方向更新。
            * 通过将更新规则中的减号改为加号，算法将从沿着最陡峭下降方向移动，转变为沿着最陡峭上升方向移动，从而实现从寻找局部最小值到寻找局部最大值的转变。
    * **答题策略:** 明确指出修改是将更新规则中的减号变为加号。然后解释梯度向量的含义，以及梯度下降和梯度上升的目标分别是最小化和最大化函数值，因此它们的更新方向相反。

