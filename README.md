# COMPX216-Midterm

**七、 连续空间中的局部搜索 (Local Search in Continuous Spaces)**

* **1. 连续状态空间 (Continuous State Spaces)**
    * **精简核心概念：** 直接点出“状态由实数向量描述，可在值域内平滑无限变化”，与离散空间对比“离散可数、邻居明确；连续无限、依赖微积分分析”。
    * **目标函数：** 保留“优化依赖于状态向量 $x$ 的连续目标函数 $f(x)$”。
    * **生活例子：** 保留一个即可，例如“调节收音机音量”。
* **2. 梯度下降 (Gradient Descent)**
    * **目标：** 清晰指出“迭代优化算法，寻找函数局部最小值”。
    * **梯度：** 核心是“梯度向量指向函数值增加最快方向”，其分量是“偏导数”。
    * **核心思想：** 概括为“沿负梯度方向（最陡峭下降）小步移动，逼近局部最小值”。
    * **更新规则：** 公式 $x_{new} = x_{current} - \gamma \nabla f(x_{current})$ 必须保留。对各符号的解释可以更简洁：$x_{current}$ (当前状态), $\nabla f(x_{current})$ (当前梯度), $\gamma$ (学习率/步长，控制移动距离，过小则慢，过大则震荡或发散), “-” (向梯度反方向移动)。
    * **迭代过程与多维梯度下降：** 可以合并说明，核心是“从初始点重复应用更新规则直至满足停止条件。多维情况下，各分量独立按其偏导数更新”。
    * **练习题关联：** 直接点出“期中练习B.3e：梯度下降改为梯度上升，关键是更新规则中‘-’变为‘+’”。
* **4. 超越基本梯度下降 (Going beyond basic gradient descent)**
    * **学习率选择：** 概括为“固定学习率简单但非最优，可用线性搜索动态寻优”。
    * **利用二阶信息：**
        * 点明“梯度（一阶）提供斜率，Hessian矩阵（二阶）提供曲率（斜率变化）”。
        * “利用曲率可更智能选择步长和方向，加速收敛”。
        * **牛顿法：** “经典二阶方法，用梯度和Hessian逆更新，收敛快（若初始点合适且Hessian可逆正定）”。
        * **拟牛顿法：** “近似Hessian逆，降低计算复杂度”。
    * **约束优化：** 指出“实际问题常有变量约束，需专门算法（如拉格朗日乘子法），基本梯度下降不直接处理”。

**进化算法 (Evolutionary Algorithms)**

* **1. 基本思想**
    * **核心概念：** 精简为“受生物进化‘自然选择、遗传变异’启发的优化算法，模拟‘适者生存’改进解的质量”。
    * **过程概述：** 列表项可以更简洁：
        1.  **种群 (Population)：** 多个“个体 (individuals)”（潜在解）。
        2.  **适应度评估 (Fitness Evaluation)：** “适应度函数”评估个体优劣。
        3.  **选择 (Selection)：** 高适应度个体作“父代 (parents)”。
        4.  **繁殖 (Reproduction)：** 父代通过“交叉 (crossover)”（基因交换组合）和“突变 (mutation)”（基因随机小修改）产生“子代 (offspring)”。
        5.  **新一代种群：** 子代形成或与部分父代组成新种群。
        6.  **迭代：** 重复2-5直至满足终止条件。
    * **与局部搜索的联系：** “并行搜索，同时在多点探索与利用，通过种群交互和遗传操作探索更广空间”。
* **2. 核心组成与设计选项**
    * **初始化：** “通常随机生成，需保证多样性”。
    * **终止条件：** 列举关键几种即可，如“达到适应度阈值、最大代数、多样性过低、适应度不再提升”。
    * **适应度函数：** “即目标函数，评估解的质量，引导进化方向 (练习题 A.6)”。
    * **种群：** “一组潜在解。大小 (k) 影响探索与收敛；多样性避免早熟”。
    * **个体表示：** “问题解的编码（基因串/结构）”。列举几种典型算法及其表示法，如：
        * **遗传算法 (GAs)：** 字符串（二进制串等）。染色体 (个体/解)，基因 (解的组成部分)。
        * **进化策略 (ES)：** 实数向量。
        * **遗传编程 (GP)：** 程序（树结构）。
        * **进化编程 (EP)：** 有限状态机。
    * **父代数量：** “通常两个（模拟有性繁殖）”。
    * **选择操作：** “高适应度个体更大概率被选为父代”。列举几种核心方法，并简述其机制：
        * **轮盘赌：** 概率与适应度成正比。
        * **锦标赛：** 随机选几个，最优者胜出。
        * **排序选择：** 基于排名而非适应度值分配概率。
        * **精英保留：** 最优个体直接复制到下一代。
        * **剔除 (Culling)：** 移除差的个体。
* **3. 主要遗传操作**
    * **交叉/重组：**
        * **目的：** “组合父代优良基因，产生更优子代，主要探索手段 (练习题 B.1d)”。
        * **过程：** “交换父代部分基因片段形成子代”。
        * **常见方式（字符串）：** 单点交叉（随机点，一父供前，另一供后）。
        * **交叉率：** “控制交叉父代比例”。
    * **突变：**
        * **目的：** “子代基因随机小变动，增多样性，助跳出局部最优，另一探索机制”。
        * **过程：** “以突变率随机改变基因值（如二进制0/1互换）”。
        * **突变率：** “控制基因突变概率，通常较低。过高破坏优良基因，过低多样性不足”。
* **4. 遗传算法 (Genetic Algorithm, GA) 概述**
    * “最著名和常用的进化算法”。
    * **伪代码：** 指明参考幻灯片，概括步骤：初始化 -> 循环（评估 -> 选择 -> 交叉 -> 突变 -> 形成新种群）-> 返回最佳个体。
    * **8-皇后问题示例：** “展示编码、适应度函数、遗传操作应用”。
* **5. 理论考量**
    * **模式 (Schema)：** “带通配符的基因模板，代表相似个体组”。
    * **模式定理 (Building block hypothesis)：** “核心理论：适应度高、短、低阶的模式（积木块）指数级增长、组合，引导寻优”。
    * **表示的重要性：** “好的编码使有意义的解组件对应紧凑且不易被交叉破坏的基因片段，利于积木块保留组合”。
* **7. 应用实例**
    * “成功应用于复杂设计问题，如NASA进化天线”。

**局部搜索和优化 (Local Search and Optimisation)**

* **1. 优化问题 vs. 路径搜索**
    * **核心区别：**
        * **路径搜索：** 目标是“行动序列”，关心“如何到达”及“路径代价”。例：地图导航。
        * **优化问题：** 目标是“最优状态”，关心“最终状态好坏”，不关心路径。例：背包问题。
    * **目标函数/代价函数：** “评估状态优劣。最大化问题/最小化问题。代价函数通常指最小化”。
* **2. 局部搜索算法**
    * **特点：** “不保留路径，内存消耗小（仅当前状态），非系统性，易陷局部最优”。
    * **状态空间地貌：** “状态空间比作地形图，状态对应点，目标函数值对应高度。局部搜索如在地形上行走寻最值点”。
* **3. 爬山算法 (Hill-Climbing Search)**
    * **基本思想：** “贪婪局部搜索。从初始状态持续向邻居中值更优（高/低）的状态移动，至无更优邻居（山顶）则停止”。
    * **最陡峭上升爬山法：** “标准形式，选择改善幅度最大的邻居”。
    * **问题/缺点 (练习题 B.3a)：**
        * **局部最值：** “易陷入，比周围好但非全局最优 (练习题B.3a解释局部最值与目标函数关系)”。
        * **山脊：** “狭长区域，每步改进小或需特定序列，最陡峭上升难导航”。
        * **平顶/高原：** “平坦区域，邻居与当前状态值相同，算法随机游走或卡住”。
    * **N-皇后问题示例：** “爬山法（尤其带随机重启）可有效解决。状态：皇后摆放。目标函数：最小化攻击对数”。
* **4. 爬山算法的变体**
    * **目的：** “尝试克服标准爬山法易陷局部最优的问题”。
    * **随机重启爬山法 (练习题 A.5)：** “多次从不同随机初始状态运行标准爬山，取所有局部最优中的最佳者。显著增加找到全局最优概率”。
    * **随机爬山法：** “从所有改善邻居中随机选一个。选择概率可与改善幅度成正比。比最陡峭慢，但某些情况（如多平顶）可能更好”。
    * **首选爬山法 (练习题 B.3b)：** “当评估所有邻居代价高时适用。随机逐个生成邻居，找到首个更优者即移动。减少计算成本，邻居空间巨大时有用 (练习题B.3b)”。
* **5. 模拟退火 (Simulated Annealing)**
    * **思想来源：** “借鉴金属退火，高温加热后缓慢冷却，原子排列到低能稳定结构”。
    * **核心机制：**
        * “随机化局部搜索”。
        * **允许“坏”移动：** “以一定概率接受使目标函数值变差的移动”。
        * **接受概率：** 取决于“移动有多坏 ($\Delta E < 0$，下降越多概率越小)”和“温度 ($T$)，越高接受坏移动概率越大”。
        * **温度调度：** “初温高，广泛探索，易跳出局部最优；随时间降温，趋向只接受好移动，精细利用 (练习题 B.3c关注温度作用)”。
    * **目标：** “通过初期探索和后期利用，期望找到全局最优或近优解”。
* **6. 局部集束搜索 (Local Beam Search)**
    * **思想：** “并行跟踪 $k$ 个状态”。
    * **过程：** “随机生成 $k$ 个初始状态 -> 迭代中生成 $k$ 个状态的所有邻居 -> 从所有邻居中选最优 $k$ 个作下一轮状态 -> 重复至满足停止条件”。
    * **与随机重启爬山区别：** “随机重启是 $k$ 次独立搜索；局部集束中 $k$ 个状态信息共享（选所有邻居中最好的 $k$ 个），资源更集中于有希望区域”。
    * **变体：随机集束搜索：** “按评估值概率选 $k$ 个，增多样性”。

**有信息（启发式）搜索策略 (Informed (Heuristic) Search Strategies)**

* **1. 启发式函数 (Heuristic Function, $h(n)$)**
    * **定义与目的 (练习题 A.4)：** “评估函数，估计从节点 $n$ 到目标的最低代价。非精确，是‘有根据的猜测’。提供方向感，引导优先探索‘看起来’更近的路径，提高效率 (练习题B.2a)”。
    * **与无信息搜索区别：** “无信息仅用问题本身信息；有信息通过 $h(n)$ 利用领域特定知识”。
* **2. 贪婪最佳优先搜索 (Greedy Best-First Search)**
    * **策略 (练习题 A.3c)：** “贪婪算法，总选择边界中 $h(n)$ 评估为最接近目标的节点。评估函数 $f(n)=h(n)$，忽略已付出代价 $g(n)$”。
    * **工作方式：** “优先队列（按 $h(n)$ 排序）管理边界，取 $h(n)$ 最小节点扩展”。
    * **特性：** “完备性：有限图完备，无限/有环图（无重复检测）可能不完备。最优性：通常不优，可能被‘陷阱’吸引。复杂度：好启发式可显著减少节点”。
* **3. A\* 搜索 (A\* Search)**
    * **策略 (练习题 A.3b)：** “兼顾已付出代价和未来预估代价。评估函数 $f(n)=g(n)+h(n)$。总选择边界中 $f(n)$ 最小节点扩展”。
    * **工作方式：** “优先队列（按 $f(n)$ 排序）。扩展子节点时计算 $g(child)$ 和 $f(child)$。若找到更优路径到达已存在节点，需更新”。
    * **可接受的启发式 (Admissible Heuristics) (练习题 B.2a, B.2e)：**
        * **定义：** “对所有节点 $n$，从不 overestimate (高估)到目标的实际最低代价 $h^*(n)$。即 $0 \le h(n) \le h^*(n)$”。
        * **重要性：** “若 $h(n)$ 可接受，A\* 保证最优”。
    * **一致的启发式 (Consistent Heuristics / Monotonicity) (练习题 B.2e)：**
        * **定义：** “对每节点 $n$ 及子节点 $n'$（行动 $a$，代价 $c(n,a,n')$），满足 $h(n) \le c(n,a,n') + h(n')$。且 $h(goal)=0$”。
        * **特性：** “一致则可接受。A\* 效率更高：一旦节点被扩展，即找到最优路径。$f(n)$ 值沿路径非递减 (练习题B.2e保证)”。
    * **搜索等高线：** “UCS均匀扩展（圆形）；A\* 集中朝目标扩展（椭圆形），体现启发式‘聚焦’”。
    * **特性：** “完备性：是。最优性：$h(n)$ 可接受时最优；一致则效率更高。最优效率：同启发式下扩展节点最少”。
* **4. 启发式的创建**
    * **核心挑战：** “好的启发式应：可接受（保证最优），信息量大（$h(n)$ 近似 $h^*(n)$，有效指导），计算成本低”。
    * **常用方法：**
        * **松弛问题：** “移除约束简化问题，其精确代价可作可接受启发式”。例：8-puzzle错位棋子数、曼哈顿距离。
        * **模式数据库：** “预存子问题最优解代价作启发式”。
    * **8-puzzle启发式例子：** “$h_1(n)$ = 错位棋子数 (可接受)；$h_2(n)$ = 曼哈顿距离和 (可接受，通常更优)”。
* **5. 内存有界搜索**
    * **问题：** “A\* 等算法大状态空间下内存可能耗尽”。
    * **集束搜索 (Beam Search) (练习题 A.9)：**
        * “启发式搜索，每步只保留固定数量 ($k$, 集束宽度)最有希望节点”。
        * **过程：** “生成后继 -> 评估 -> 只保留最优 $k$ 个，其余丢弃 -> 从 $k$ 个中选节点扩展”。
        * **优缺点：** “显著减内存；不完备且不保证最优 (可能丢弃最优路径上节点) (练习题A.9考察)”。

**无信息搜索策略 (Uninformed Search Strategies)**

* **1. 无信息 vs. 有信息搜索**
    * **无信息：** “无特定知识指导，仅区分目标/非目标，系统性探索（如BFS逐层，DFS深入）”。
    * **有信息：** “用 $h(n)$ 估计到目标距离/代价，优先扩展有希望节点”。
* **2. 通用最佳优先搜索 (Generic Best-First Search)**
    * **框架：** “多种搜索算法特例”。
    * **核心思想：** “维护边界 (frontier, 已生成未扩展节点) -> 据策略/评估函数选‘最佳’节点扩展 -> 若目标则返回解 -> 否则扩展子节点入边界 -> 重复”。
    * **区别：** “选择策略及边界管理方式（队列类型）”。
    * **已达到列表 (reached list / explored set)：** “避免循环和冗余工作，存已扩展/已入边界状态”。
* **3. 广度优先搜索 (BFS)**
    * **策略 (练习题 A.3, B.2c(a))：** “总扩展边界中最浅节点。逐层探索”。
    * **数据结构：** “FIFO队列管理边界 (练习题B.2c(a))”。
    * **特性：** “完备性：是。最优性：仅当所有步代价相同时最优（路径最短）。时空复杂度：$O(b^d)$ (空间是主要缺点)”。
* **4. 一致代价搜索 (UCS) (Dijkstra)**
    * **策略 (练习题 B.2b)：** “总扩展路径代价 $g(n)$ 最低节点。不关心深度，只关心累积代价”。
    * **数据结构：** “优先队列（按 $g(n)$ 排序）”。
    * **特性：** “完备性：是（若步代价 $\epsilon > 0$）。最优性：是（若步代价非负）。时空复杂度：大致 $O(b^{1+\lfloor C^*/\epsilon \rfloor})$”。
    * **与BFS关系：** “若步代价相同，UCS等同BFS”。
* **5. 深度优先搜索 (DFS)**
    * **策略 (练习题 B.2c(b))：** “总扩展边界中最深节点。沿路径探到底再回溯”。
    * **数据结构：** “LIFO队列（栈）管理边界 (练习题B.2c(b))”。
    * **特性：** “完备性：有限图完备；无限深/有环图（无重复检测）可能不完备。最优性：通常不优。时间复杂度：最坏 $O(b^m)$。空间复杂度：$O(bm)$ (主要优点)”。
    * **变体：** 深度限制搜索 (DLS)，迭代加深搜索 (IDDFS, 结合BFS最优和DFS空间效率)。
* **6. 避免重复状态**
    * **问题：** “冗余计算，有环图无限循环”。
    * **解决方案：** “维护已达到列表 (哈希表实现)。Tree-Search不检测重复；Graph-Search维护已探索集”。
* **7. 队列的角色和实现 (练习题 B.2d)**
    * **核心：** “不同队列类型实现边界 -> 不同搜索行为”。
        * FIFO -> BFS (最浅)
        * LIFO -> DFS (最深)
        * 优先队列 (按 $g(n)$) -> UCS (路径代价最低)
        * 优先队列 (按 $h(n)$) -> Greedy Best-First
        * 优先队列 (按 $f(n)=g(n)+h(n)$) -> A\*
    * **练习题关联 (B.2d)：** “优先队列 + 深度评估 -> BFS；优先队列 + 负深度评估 -> DFS”。

**问题解决型智能体 (Problem-Solving Agents)**

* **1. 智能体与环境**
    * **单智能体 vs. 多智能体 (练习题 B.1b)：** “单：独行；多：多个体交互（合作/竞争）。关键：环境是否有其他目标导向实体影响当前智能体”。
    * **确定性 vs. 非确定性/随机性：** “确定：下一状态完全由当前状态和动作决定；非确定：含随机因素，或部分可观察导致”。
    * **片段性 vs. 序列性：** “片段：决策独立于历史；序列：当前决策影响未来，历史重要”。
    * **静态 vs. 动态 (练习题 A.2)：** “静态：智能体决策时环境不变；动态：决策时环境可能变化”。
    * **离散 vs. 连续：** “应用于状态、时间、感知、行动。离散：有限可数；连续：无限多值”。
* **2. 问题定义与形式化**
    * **问题解决型智能体：** “通过搜索行动序列达目标。通常原子状态表示，环境简化假设（全可观察、单体、确定等）”。
    * **问题解决过程：** “目标制定 -> 问题形式化 -> 搜索 -> 执行”。
    * **搜索问题组成 (练习题 B.1a)：**
        * **状态空间 (States)：** 所有可能状态集合。
        * **初始状态 (Initial state)：** 搜索起点。
        * **目标测试 (Goal test)：** 判断是否目标状态。
        * **行动 (Actions)：** 给定状态下可执行行动集。
        * **转移模型 (Transition model/Successor function)：** $RESULT(s, a) \rightarrow s'$，执行行动后状态转换。
        * **路径代价函数 (Path cost function)：** 行动数值代价，解的代价是路径上行动代价和。最优解代价最低。
* **3. 搜索树与数据结构**
    * **状态空间图 vs. 搜索树：** “图：状态及转换关系抽象，状态唯一；树：搜索中动态构建，节点对应到达状态的路径，同状态可多次出现”。
    * **节点 (Node) 构成 (练习题 B.1c)：** “记录搜索过程和重构解。含：state, parent, action, path\_cost ($g(n)$), depth。状态是环境配置；节点是含状态和路径信息的数据结构”。
    * **节点扩展 (Expanding nodes)：** “选边界节点，生成其所有子节点加入边界”。
    * **边界 (Frontier)：** “已生成未扩展节点。核心区别在于如何从中选择及管理”。
    * **已探索集合 (Explored set)：** “已访问状态，避免重复探索和循环”。
* **4. 搜索策略评估标准**
    * **完备性 (Completeness)：** 是否保证找到解？
    * **最优性 (Optimality)：** 是否找到路径代价最低的解？
    * **时间复杂度 (Time complexity)：** 找到解需多久（扩展节点数）？
    * **空间复杂度 (Space complexity)：** 需多少内存（边界最大节点数）？
